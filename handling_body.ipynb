{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"handling_body.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"u5famyqcRjej","colab":{"base_uri":"https://localhost:8080/"},"outputId":"073451fd-1ea4-4173-9bfe-17b90eb8b008"},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","import os\n","import numpy as np  # linear algebra\n","import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n","from datetime import datetime\n","from tqdm import tqdm\n","import collections as clt\n","from textblob import TextBlob\n","from textblob import TextBlob\n","from textblob.sentiments import NaiveBayesAnalyzer\n","import nltk\n","from nltk.tokenize import TreebankWordTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from string import punctuation\n","from nltk.tokenize import TreebankWordTokenizer\n","import re\n","from nltk.tokenize import TreebankWordTokenizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.decomposition import LatentDirichletAllocation\n","import pickle\n","from nltk.stem import WordNetLemmatizer\n","from nltk.corpus import stopwords\n","from nltk.corpus import wordnet\n","import nltk\n","nltk.download('wordnet')\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('movie_reviews')\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session "],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ffysldmhTuEP","outputId":"1f58e745-870d-4183-d58c-08ae821a8453"},"source":["from google.colab import drive\n","drive.mount('/content/drive') "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bk_ei1Q1UZ3z","outputId":"bb67a4c4-b129-4c44-d182-f1280cb82bb7"},"source":["# Seting the directory \n","%cd /content/drive/MyDrive/TP_M1_SID/Second_semestre/Compet_kaggle  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/TP_M1_SID/Second_semestre/Compet_kaggle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"amdnGM2GR4nB","outputId":"bebd2004-f1e1-4863-ba83-f7dec2977c24"},"source":["df = pd.read_csv('comments_students.csv')[['id', 'ups', 'body']] \n","df.head() "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ups</th>\n","      <th>body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cqug90j</td>\n","      <td>3.0</td>\n","      <td>No one has a European accent either  because i...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cqug90k</td>\n","      <td>3.0</td>\n","      <td>That the kid ..reminds me of Kevin.   so sad :-(</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cqug90z</td>\n","      <td>5.0</td>\n","      <td>NSFL</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cqug91c</td>\n","      <td>1.0</td>\n","      <td>I'm a guy and I had no idea this was a thing g...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cqug91e</td>\n","      <td>101.0</td>\n","      <td>Mid twenties male rocking skinny jeans/pants, ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        id    ups                                               body\n","0  cqug90j    3.0  No one has a European accent either  because i...\n","1  cqug90k    3.0   That the kid ..reminds me of Kevin.   so sad :-(\n","2  cqug90z    5.0                                               NSFL\n","3  cqug91c    1.0  I'm a guy and I had no idea this was a thing g...\n","4  cqug91e  101.0  Mid twenties male rocking skinny jeans/pants, ..."]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Oo3aRC9gp8A","outputId":"9d1ca0e8-9f31-4e34-b9d3-2f2ed7201658"},"source":["df.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4234970, 3)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"AWKTozY4vEKb"},"source":["## 1. Sentiment analysis\n","### Before cleaning the text, let's do some sentiment analysis"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MCuj-wfvIKF","outputId":"966be526-499d-4090-9b11-4a3b206ae07f"},"source":["df['body'].isnull().sum()\n","print(\"have 61 rows which don't have any comment\")\n","print('----------------------------------------------------------')\n","# Let's replace nan values by white space \n","df['body'].fillna('', inplace = True)\n","# Then we have \n","print(df['body'].isnull().sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["have 61 rows which don't have any comment\n","----------------------------------------------------------\n","0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"409rGrVgKraJ"},"source":["##### I had the intuition that the score of the comment is determined by it's text represented by the variable \"body\". More specifically by the feeling it gave off: according to the subjectivity (the expression of the author's opinion, 0 for a very little subjective comment and 1 for an extremely subjective comment) and polarity (the level of emotion, -1 for a negative comment and +1 for a very positive comment). We used the library called textBlob. "]},{"cell_type":"code","metadata":{"id":"GqV3kKMZveDG"},"source":["## These two function help us to get the polarity and subjectivity of a sentence \n","def textBlobPolarity(sent):\n","  polarity = TextBlob(sent).sentiment.polarity\n","  return polarity\n","\n","def textBlobSubjectivity(sent):\n","  subjectivity = TextBlob(sent).sentiment.subjectivity\n","  return subjectivity\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QkgYICg11rBY"},"source":["def sent_analysis(col, nb_chunk, function_name, df):\n","  \"\"\"\n","  description: enables to analyse sentiment in text according to subjectivity or polarity\n","  in: \n","    col: name of the column we add to the dataframe\n","    nb_chunk: number of chunks used\n","    function_name: can be textBlobPolarity or textBlobSubjectivity\n","    df: our dataframe which contains our data\n","  out: the dataframe where we add the sentiment analysis columns    \n","  \"\"\"\n","  df[str(col)] = df['body']\n","\n","  df_chunk =  np.array_split(df, nb_chunk)\n","  chunk_list = []\n","  for i, chunk in tqdm(enumerate(df_chunk)):\n","    chunk_filter = chunk\n","    chunk_filter[str(col)] = chunk['body'].apply(function_name)\n","    chunk_list.append(chunk_filter) #Normally chunk_filter \n","      \n","  # concat the list into dataframe \n","  return pd.concat(chunk_list)  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kAjq-UlFFV4R"},"source":["def convertion(x):\n","  if x<0:\n","    return -1\n","  elif x> 0:\n","    return 1\n","  return 0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gip7T6nM2jDO","outputId":"14238c11-3882-4f13-8aba-d76580274ef5"},"source":["# Applying the function sent_analysis to get the polarity of each comment \n","\n","from tqdm import tqdm \n","df = sent_analysis('polarity', 1000, textBlobPolarity, df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1000it [23:11,  1.39s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"29lgAf6Xwsnm","outputId":"c15c98ad-c396-4f86-c2d6-6d231435548a"},"source":["# Applying the function sent_analysis to get the polarity of each comment \n","from tqdm import tqdm\n","df = sent_analysis('subjectivity', 1000, textBlobSubjectivity, df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1000it [23:12,  1.39s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XXIsHNxmF0O9","outputId":"c00fa2b6-1568-4803-86a7-543d8eb8fa4c"},"source":["%%time\n","# To avoid a problem of disrimatory, we try and convert polarity values. Thus we get only three possible vlaues 0 = neutral, -1 = negative, and 1 = positive \n","df['polarity'] = df['polarity'].apply(convertion)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 2.07 s, sys: 60.1 ms, total: 2.13 s\n","Wall time: 2.13 s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"_zKgzcjzfMcS","outputId":"66a27581-26f0-4c17-8d6e-df5de49c4583"},"source":["df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ups</th>\n","      <th>body</th>\n","      <th>polarity</th>\n","      <th>subjectivity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cqug90j</td>\n","      <td>3.0</td>\n","      <td>No one has a European accent either  because i...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cqug90k</td>\n","      <td>3.0</td>\n","      <td>That the kid ..reminds me of Kevin.   so sad :-(</td>\n","      <td>-1</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cqug90z</td>\n","      <td>5.0</td>\n","      <td>NSFL</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cqug91c</td>\n","      <td>1.0</td>\n","      <td>I'm a guy and I had no idea this was a thing g...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cqug91e</td>\n","      <td>101.0</td>\n","      <td>Mid twenties male rocking skinny jeans/pants, ...</td>\n","      <td>1</td>\n","      <td>0.427083</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4234965</th>\n","      <td>crrbelu</td>\n","      <td>NaN</td>\n","      <td>Does the sun set in the west/rise in the east?...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4234966</th>\n","      <td>crrbelv</td>\n","      <td>NaN</td>\n","      <td>Coffee.</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4234967</th>\n","      <td>crrbemp</td>\n","      <td>NaN</td>\n","      <td>people who cannot make up their mind, my bulls...</td>\n","      <td>-1</td>\n","      <td>0.400000</td>\n","    </tr>\n","    <tr>\n","      <th>4234968</th>\n","      <td>crrbenh</td>\n","      <td>NaN</td>\n","      <td>Give them to Irish people in exchange for doin...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4234969</th>\n","      <td>crrbeop</td>\n","      <td>NaN</td>\n","      <td>classy way to put it</td>\n","      <td>1</td>\n","      <td>0.900000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4234970 rows × 5 columns</p>\n","</div>"],"text/plain":["              id    ups  ... polarity  subjectivity\n","0        cqug90j    3.0  ...        0      0.000000\n","1        cqug90k    3.0  ...       -1      1.000000\n","2        cqug90z    5.0  ...        0      0.000000\n","3        cqug91c    1.0  ...        0      0.000000\n","4        cqug91e  101.0  ...        1      0.427083\n","...          ...    ...  ...      ...           ...\n","4234965  crrbelu    NaN  ...        0      0.000000\n","4234966  crrbelv    NaN  ...        0      0.000000\n","4234967  crrbemp    NaN  ...       -1      0.400000\n","4234968  crrbenh    NaN  ...        0      0.000000\n","4234969  crrbeop    NaN  ...        1      0.900000\n","\n","[4234970 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"sHgZvdvXxgAX"},"source":["## Saving a copy"]},{"cell_type":"code","metadata":{"id":"aUsKpiY3wsqQ"},"source":["df.to_csv('sentiment_analysis.csv', index=False) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"ZXvqoln4wstK","outputId":"6f9f4599-585a-40c2-bc2d-28ee138348ba"},"source":["df = pd.read_csv(\"sentiment_analysis.csv\", lineterminator='\\n')\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ups</th>\n","      <th>body</th>\n","      <th>polarity</th>\n","      <th>subjectivity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cqug90j</td>\n","      <td>3.0</td>\n","      <td>No one has a European accent either  because i...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cqug90k</td>\n","      <td>3.0</td>\n","      <td>That the kid ..reminds me of Kevin.   so sad :-(</td>\n","      <td>-1</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cqug90z</td>\n","      <td>5.0</td>\n","      <td>NSFL</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cqug91c</td>\n","      <td>1.0</td>\n","      <td>I'm a guy and I had no idea this was a thing g...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cqug91e</td>\n","      <td>101.0</td>\n","      <td>Mid twenties male rocking skinny jeans/pants, ...</td>\n","      <td>1</td>\n","      <td>0.427083</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4234965</th>\n","      <td>crrbelu</td>\n","      <td>NaN</td>\n","      <td>Does the sun set in the west/rise in the east?...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4234966</th>\n","      <td>crrbelv</td>\n","      <td>NaN</td>\n","      <td>Coffee.</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4234967</th>\n","      <td>crrbemp</td>\n","      <td>NaN</td>\n","      <td>people who cannot make up their mind, my bulls...</td>\n","      <td>-1</td>\n","      <td>0.400000</td>\n","    </tr>\n","    <tr>\n","      <th>4234968</th>\n","      <td>crrbenh</td>\n","      <td>NaN</td>\n","      <td>Give them to Irish people in exchange for doin...</td>\n","      <td>0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4234969</th>\n","      <td>crrbeop</td>\n","      <td>NaN</td>\n","      <td>classy way to put it</td>\n","      <td>1</td>\n","      <td>0.900000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4234970 rows × 5 columns</p>\n","</div>"],"text/plain":["              id    ups  ... polarity  subjectivity\n","0        cqug90j    3.0  ...        0      0.000000\n","1        cqug90k    3.0  ...       -1      1.000000\n","2        cqug90z    5.0  ...        0      0.000000\n","3        cqug91c    1.0  ...        0      0.000000\n","4        cqug91e  101.0  ...        1      0.427083\n","...          ...    ...  ...      ...           ...\n","4234965  crrbelu    NaN  ...        0      0.000000\n","4234966  crrbelv    NaN  ...        0      0.000000\n","4234967  crrbemp    NaN  ...       -1      0.400000\n","4234968  crrbenh    NaN  ...        0      0.000000\n","4234969  crrbeop    NaN  ...        1      0.900000\n","\n","[4234970 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"_wNo7JUBSr-z"},"source":["# Text Cleaning \n","I clean data from variable 'body' in order to improve the the performance of our models. For instance converting to lower case ( KIDS will be equal to kids). \n"]},{"cell_type":"code","metadata":{"id":"yB8WXPTrS31u"},"source":["# Loading english stop words\n","stop = stopwords.words('english')\n","# Adding some characters to the loaded punctuation\n","punctuations = punctuation+\"’”“‘…„—᾿‐–‑′•›‹⁄―‚→（）『』》《。↓↵'͞ʻʿ'\"+'″￼'\n","\n","## Function that clean the body content\n","def text_cleaning(sentence):\n","  \"\"\" Documentation\n","    text :input parameter, must be a string \n","    Returns the vocabulary without accent\n","    Out : string\n","    \"\"\"\n","\n","  sentence = str(sentence) # Converting to str if we get a non str type\n","  # email format\n","  email =re.compile('[a-zA-Z0-9.-]+@[a-zA-Z._/-]+.[a-z]+')\n","  # caracteres\n","  caracters=re.compile('\\W+')\n","  # number \n","  number =re.compile('[0-9]+' )\n","\n","  # Convert to lowercase\n","  sentence = sentence.lower() \n","  # Removing stopwords\n","  sentence = ' '.join([word for word in sentence.split() if word not in (stop)])  \n","\n","  # Tranforming the sentence into a list of token \n","  liste_tokens = TreebankWordTokenizer().tokenize(sentence)\n","\n","  # Removing sepecial caratere from the token: eg \"\"..reminds\" becomes \"reminds\"\n","  for i in range(len(liste_tokens)):\n","    liste_tokens[i] = liste_tokens[i].strip(punctuations)\n","\n","  \n","  \n","  # Remove number\n","  sentence = number.sub(\" \", sentence)\n","  # \n","  sentence = caracters.sub(\" \", sentence)\n","  # handling email format\n","  sentence = email.sub(\" \", sentence)\n","\n","  # Remove words which len are <2\n","  sentence = ' '.join([w for w in liste_tokens if len(w) > 1])\n","  \n","  return sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqF3QDEvVZCd"},"source":["df_chunk =  np.array_split(df, 100)     "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G2M3hyEfTiBl","outputId":"787c4466-fdd9-4b1a-f73e-9798610d9100"},"source":["%%time \n","\n","chunk_list = [] \n","\n","for i, chunk in tqdm(enumerate(df_chunk)):\n","    chunk_filter = chunk\n","    chunk_filter['body'] = chunk['body'].apply(text_cleaning)\n","    \n","    # Once the data filtering is done, append the chunk to list \n","    chunk_list.append(chunk_filter) #Normally chunk_filter \n","    \n","# concat the list into dataframe \n","df = pd.concat(chunk_list)  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["100it [13:21,  8.01s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["CPU times: user 13min 12s, sys: 3.42 s, total: 13min 16s\n","Wall time: 13min 21s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Y2QvJAC-A_-F"},"source":["### Lemmatization\n","#### For the sake of improving our model, let's do some lemmatization for instance accents becomes accent. "]},{"cell_type":"code","metadata":{"id":"HYoQGxHDA_GB"},"source":["lemmer=WordNetLemmatizer()\n","\n","def lemmatization(word):\n","  \"\"\"\n","  description: enable to consider for each term only its root meaning.\n","  \"\"\"\n","  for pos in ['a', 's', 'r', 'n', 'v']:\n","    word=lemmer.lemmatize(word,pos)\n","  return word"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AnDHyKSUA_QL","outputId":"7f4a4c0b-1490-45ca-c569-18303ce2c1de"},"source":["%%time \n","# Applying the lemmmatization function on each comment \n","\n","df[\"body\"] = df[\"body\"].apply(lambda x: ' '.join([lemmatization(word) for word in x.split() ]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 16min 31s, sys: 6.74 s, total: 16min 38s\n","Wall time: 16min 43s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uKOm-ImMep2o"},"source":["## Saving a copy"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"vYtuAAJnXGsO","outputId":"16a8e6e2-c435-49c6-e633-551f1edcdf2b"},"source":["df.to_csv('body_clean_lem.csv', index = False)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ups</th>\n","      <th>body</th>\n","      <th>polarity</th>\n","      <th>subjectivity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cqug90j</td>\n","      <td>3.0</td>\n","      <td>one european accent either exist accent europe...</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cqug90k</td>\n","      <td>3.0</td>\n","      <td>kid remind kevin sad</td>\n","      <td>-0.625000</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cqug90z</td>\n","      <td>5.0</td>\n","      <td>nsfl</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cqug91c</td>\n","      <td>1.0</td>\n","      <td>guy idea thing guy do</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cqug91e</td>\n","      <td>101.0</td>\n","      <td>mid twenty male rock skinny jeans/pants style ...</td>\n","      <td>0.189062</td>\n","      <td>0.427083</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4234965</th>\n","      <td>crrbelu</td>\n","      <td>NaN</td>\n","      <td>sun set west/rise east yes</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4234966</th>\n","      <td>crrbelv</td>\n","      <td>NaN</td>\n","      <td>coffee</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4234967</th>\n","      <td>crrbemp</td>\n","      <td>NaN</td>\n","      <td>people can not make mind bullshit ex slow wifi</td>\n","      <td>-0.300000</td>\n","      <td>0.400000</td>\n","    </tr>\n","    <tr>\n","      <th>4234968</th>\n","      <td>crrbenh</td>\n","      <td>NaN</td>\n","      <td>give irish people exchange bid</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4234969</th>\n","      <td>crrbeop</td>\n","      <td>NaN</td>\n","      <td>classy way put</td>\n","      <td>0.100000</td>\n","      <td>0.900000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4234970 rows × 5 columns</p>\n","</div>"],"text/plain":["              id    ups  ...  polarity  subjectivity\n","0        cqug90j    3.0  ...  0.000000      0.000000\n","1        cqug90k    3.0  ... -0.625000      1.000000\n","2        cqug90z    5.0  ...  0.000000      0.000000\n","3        cqug91c    1.0  ...  0.000000      0.000000\n","4        cqug91e  101.0  ...  0.189062      0.427083\n","...          ...    ...  ...       ...           ...\n","4234965  crrbelu    NaN  ...  0.000000      0.000000\n","4234966  crrbelv    NaN  ...  0.000000      0.000000\n","4234967  crrbemp    NaN  ... -0.300000      0.400000\n","4234968  crrbenh    NaN  ...  0.000000      0.000000\n","4234969  crrbeop    NaN  ...  0.100000      0.900000\n","\n","[4234970 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"markdown","metadata":{"id":"KUlxTFiVfAIQ"},"source":["## Re-loading data "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"6Erng11U0RgE","outputId":"ffd0945f-b9d2-466c-ee0e-56d5cb77e0a7"},"source":["df_clean = pd.read_csv('body_clean_lem.csv')\n","df_clean "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ups</th>\n","      <th>body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cqug90j</td>\n","      <td>3.0</td>\n","      <td>one european accent either exist accent europe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cqug90k</td>\n","      <td>3.0</td>\n","      <td>kid remind kevin sad</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cqug90z</td>\n","      <td>5.0</td>\n","      <td>nsfl</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cqug91c</td>\n","      <td>1.0</td>\n","      <td>guy idea thing guy do</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cqug91e</td>\n","      <td>101.0</td>\n","      <td>mid twenty male rock skinny jeans/pants style ...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4234965</th>\n","      <td>crrbelu</td>\n","      <td>NaN</td>\n","      <td>sun set west/rise east yes</td>\n","    </tr>\n","    <tr>\n","      <th>4234966</th>\n","      <td>crrbelv</td>\n","      <td>NaN</td>\n","      <td>coffee</td>\n","    </tr>\n","    <tr>\n","      <th>4234967</th>\n","      <td>crrbemp</td>\n","      <td>NaN</td>\n","      <td>people can not make mind bullshit ex slow wifi</td>\n","    </tr>\n","    <tr>\n","      <th>4234968</th>\n","      <td>crrbenh</td>\n","      <td>NaN</td>\n","      <td>give irish people exchange bid</td>\n","    </tr>\n","    <tr>\n","      <th>4234969</th>\n","      <td>crrbeop</td>\n","      <td>NaN</td>\n","      <td>classy way put</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4234970 rows × 3 columns</p>\n","</div>"],"text/plain":["              id    ups                                               body\n","0        cqug90j    3.0  one european accent either exist accent europe...\n","1        cqug90k    3.0                               kid remind kevin sad\n","2        cqug90z    5.0                                               nsfl\n","3        cqug91c    1.0                              guy idea thing guy do\n","4        cqug91e  101.0  mid twenty male rock skinny jeans/pants style ...\n","...          ...    ...                                                ...\n","4234965  crrbelu    NaN                         sun set west/rise east yes\n","4234966  crrbelv    NaN                                             coffee\n","4234967  crrbemp    NaN     people can not make mind bullshit ex slow wifi\n","4234968  crrbenh    NaN                     give irish people exchange bid\n","4234969  crrbeop    NaN                                     classy way put\n","\n","[4234970 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRC44GAhKaV5","outputId":"29094432-0534-4c08-ab80-e9ab334dc0ca"},"source":["df_clean.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4234970, 3)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"DXEaTT85HquU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8d88cf8e-cf26-43d5-8ba9-159d7054760b"},"source":["df_clean['body'].isnull().sum()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["29927"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"IQX8iWhL033O","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ce8c2850-5784-48ea-a157-70647058d2ca"},"source":["x = df_clean['body'].isnull().sum()\n","print(f\"have {x} rows which don't have any comment\")\n","print('----------------------------------------------------------')\n","# Let's replace nan values by white space \n","df_clean['body'].fillna('', inplace = True)\n","print('Then we have ')\n","print(df_clean['body'].isnull().sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["have 29927 rows which don't have any comment\n","----------------------------------------------------------\n","Then we have \n","0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Q-025zCbMgHW"},"source":["# Calculating the tf_idf values \n","I calculated tf-idf values but it was not used in the prediction because it deteriorated results"]},{"cell_type":"code","metadata":{"id":"3S-DqwMmzgeT","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f65d781b-9e18-4cb4-f5e8-650d8f663a86"},"source":["%%time\n","vectorizer = TfidfVectorizer(max_df=0.95, min_df= 5000, max_features= 200000, stop_words='english')\n","\n","tfidf = vectorizer.fit_transform(df_clean['body']) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 1min 6s, sys: 1.02 s, total: 1min 7s\n","Wall time: 1min 7s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zmach0OUzgp9","outputId":"2cac7d07-78f1-4475-b7c2-37c13ce72209"},"source":["tfidf.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4234970, 1394)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQr2flqUgIMM","outputId":"430a11c5-0e83-4a93-94fa-8723143a201e"},"source":["%%time\n","df_clean['tf_idf'] = tfidf\n","df_clean = df_clean[['id', 'ups', 'body']]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 651 ms, sys: 6.69 ms, total: 658 ms\n","Wall time: 663 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ISxwyYFypspl"},"source":["# Topic extraction "]},{"cell_type":"markdown","metadata":{"id":"h3xhUEjESxz1"},"source":["I tried to extract topics from all the text of the comments. A comment can have several topics. As a consequence, we had the intuition that a comment which belongs to a lot of topics has more chance to have a great score and vice-versa."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vf42vawfsxnU","outputId":"555816d3-1b5f-47af-bec4-d2f6efd7dd34"},"source":["# before we apply our LDA let'us create a vocabulary of all our data \n","\n","count_vect = CountVectorizer(min_df=5000,max_df=200000, stop_words='english')\n","X = count_vect.fit_transform(df_clean['body'])\n","\n","# Fetching words from our vocabulary\n","colonnes=count_vect.get_feature_names()\n","X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4234970, 1384)"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M54hgSqQolBc","outputId":"f8978195-354d-47d9-c450-2e3d7533b00d"},"source":["%%time\n","# Creating a LDA, let's specify the number of categorie or topic into 100\n","nb_topics=100\n","LDA = LatentDirichletAllocation(n_components=nb_topics, learning_method= 'online', learning_offset=50.,random_state=42)\n","\n","# Fiiting on data \n","LDA.fit(X)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 3h 41s, sys: 1h 8s, total: 4h 49s\n","Wall time: 2h 56min 49s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0ToRQlm40NpX"},"source":["###### Saving our LDA model"]},{"cell_type":"code","metadata":{"id":"SU7QWdJI0M3a"},"source":["filename = 'lda_model.sav'\n","pickle.dump(LDA, open(filename, 'wb'))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tdlFoipX16S5"},"source":["#### Re-loading the model"]},{"cell_type":"code","metadata":{"id":"AvZhSFoJ15Wb"},"source":["filename = 'lda_model.sav'\n","\n","lda_model = pickle.load(open(filename, 'rb'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PiP9L-r6olEm"},"source":["#Evaluation, getting the 15 most frequent for each topic \n","n_terms=20\n","dict_topics=clt.defaultdict(list)\n","L=lda_model.components_\n","\n","for i, r in enumerate(L):\n","    for i in r.argsort()[:-n_terms - 1:-1]:\n","          dict_topics[i+1].append(colonnes[i])  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lumcdAhCsaT8"},"source":["def sent_topic_weight(doc):\n","    \"\"\"\n","    descritpion: A function that assigns each document a weight, (the number of topics the document talks about it )/100.\n","    \"\"\"\n","    doc=str(doc).split()\n","    n=0\n","    topic_compter=[]\n","    for elt in doc:\n","        for i in range(1,101):\n","            if i not in topic_compter:\n","                if elt in dict_topics[i]:\n","                    n+=1\n","                    topic_compter.append(i)\n","    return n/100 "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P0LSXIhpsaf4","outputId":"0b0e4755-aba2-4f30-de37-cbf7a3599e25"},"source":["%%time \n","\n","## We apply the function sent_topic_weight to each row of our dataframe, so we assign each comment a weight \n","\n","df_clean['weight_topic']=df_clean['body'].apply(func=sent_topic_weight)\n","df_clean.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 30min 50s, sys: 3.52 s, total: 30min 53s\n","Wall time: 31min 13s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"VCj1hc_O_gSl","outputId":"dc48c1b8-cca8-4e60-b18d-3c07513c7cf6"},"source":["df_clean "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>ups</th>\n","      <th>body</th>\n","      <th>weight_topic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cqug90j</td>\n","      <td>3.0</td>\n","      <td>one european accent either exist accent europe...</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cqug90k</td>\n","      <td>3.0</td>\n","      <td>kid remind kevin sad</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cqug90z</td>\n","      <td>5.0</td>\n","      <td>nsfl</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cqug91c</td>\n","      <td>1.0</td>\n","      <td>guy idea thing guy do</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cqug91e</td>\n","      <td>101.0</td>\n","      <td>mid twenty male rock skinny jeans/pants style ...</td>\n","      <td>0.02</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4234965</th>\n","      <td>crrbelu</td>\n","      <td>NaN</td>\n","      <td>sun set west/rise east yes</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>4234966</th>\n","      <td>crrbelv</td>\n","      <td>NaN</td>\n","      <td>coffee</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>4234967</th>\n","      <td>crrbemp</td>\n","      <td>NaN</td>\n","      <td>people can not make mind bullshit ex slow wifi</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>4234968</th>\n","      <td>crrbenh</td>\n","      <td>NaN</td>\n","      <td>give irish people exchange bid</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>4234969</th>\n","      <td>crrbeop</td>\n","      <td>NaN</td>\n","      <td>classy way put</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4234970 rows × 4 columns</p>\n","</div>"],"text/plain":["              id  ...  weight_topic\n","0        cqug90j  ...          0.00\n","1        cqug90k  ...          0.00\n","2        cqug90z  ...          0.00\n","3        cqug91c  ...          0.00\n","4        cqug91e  ...          0.02\n","...          ...  ...           ...\n","4234965  crrbelu  ...          0.00\n","4234966  crrbelv  ...          0.00\n","4234967  crrbemp  ...          0.00\n","4234968  crrbenh  ...          0.00\n","4234969  crrbeop  ...          0.00\n","\n","[4234970 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"id":"XQtziJim4q4C","outputId":"b620cce4-5acd-4c4d-d087-f8e46186b1f5"},"source":["# Scaling data \n","from sklearn.preprocessing import StandardScaler\n","\n","df_copy = df_clean[['id', 'weight_topic']]\n","scaler = StandardScaler()\n","df_copy.iloc[:,1:]=scaler.fit_transform(df_copy.iloc[:,1:])\n","df_copy\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1734: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  isetter(loc, value[:, i].tolist())\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>weight_topic</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cqug90j</td>\n","      <td>-0.400798</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cqug90k</td>\n","      <td>-0.400798</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>cqug90z</td>\n","      <td>-0.400798</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>cqug91c</td>\n","      <td>-0.400798</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>cqug91e</td>\n","      <td>2.477223</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4234965</th>\n","      <td>crrbelu</td>\n","      <td>-0.400798</td>\n","    </tr>\n","    <tr>\n","      <th>4234966</th>\n","      <td>crrbelv</td>\n","      <td>-0.400798</td>\n","    </tr>\n","    <tr>\n","      <th>4234967</th>\n","      <td>crrbemp</td>\n","      <td>-0.400798</td>\n","    </tr>\n","    <tr>\n","      <th>4234968</th>\n","      <td>crrbenh</td>\n","      <td>-0.400798</td>\n","    </tr>\n","    <tr>\n","      <th>4234969</th>\n","      <td>crrbeop</td>\n","      <td>-0.400798</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>4234970 rows × 2 columns</p>\n","</div>"],"text/plain":["              id  weight_topic\n","0        cqug90j     -0.400798\n","1        cqug90k     -0.400798\n","2        cqug90z     -0.400798\n","3        cqug91c     -0.400798\n","4        cqug91e      2.477223\n","...          ...           ...\n","4234965  crrbelu     -0.400798\n","4234966  crrbelv     -0.400798\n","4234967  crrbemp     -0.400798\n","4234968  crrbenh     -0.400798\n","4234969  crrbeop     -0.400798\n","\n","[4234970 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"markdown","metadata":{"id":"sCwOcNe5kA1-"},"source":["### Saving a copy"]},{"cell_type":"code","metadata":{"id":"qoRpqQH2xlDK"},"source":["df_copy.to_csv(\"topic.csv\", index = False)"],"execution_count":null,"outputs":[]}]}